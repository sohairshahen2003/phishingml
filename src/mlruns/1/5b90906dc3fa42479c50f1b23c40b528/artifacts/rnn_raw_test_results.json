{"data": {}, "embedding": {"vocabulary_size": 70, "embedding_dimension": 100}, "hiperparameter": {"model_summary": "Model: \"sequential\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n embedding (Embedding)       (None, None, 100)         7100      \n                                                                 \n lstm (LSTM)                 (None, None, 128)         117248    \n                                                                 \n lstm_1 (LSTM)               (None, None, 128)         131584    \n                                                                 \n lstm_2 (LSTM)               (None, None, 128)         131584    \n                                                                 \n lstm_3 (LSTM)               (None, None, 128)         131584    \n                                                                 \n lstm_4 (LSTM)               (None, None, 128)         131584    \n                                                                 \n lstm_5 (LSTM)               (None, None, 128)         131584    \n                                                                 \n lstm_6 (LSTM)               (None, 128)               131584    \n                                                                 \n dense (Dense)               (None, 2)                 258       \n                                                                 \n=================================================================\nTotal params: 914,110\nTrainable params: 914,110\nNon-trainable params: 0\n_________________________________________________________________\n", "epoch": 1, "train_batch_size": 64, "test_batch_size": 64, "sequence_length": 200}, "test_result": {"test_time": 594.7647094726562, "report": "              precision    recall  f1-score   support\n\n    phishing       0.94      0.94      0.94     28532\n  legitimate       0.93      0.92      0.92     22978\n\n    accuracy                           0.93     51510\n   macro avg       0.93      0.93      0.93     51510\nweighted avg       0.93      0.93      0.93     51510\n", "test_acc": 0.9323820471763611, "test_loss": 0.16724355518817902, "test_confusion_matrix": [[26837, 1695], [1788, 21190]]}, "epoch_history": {"loss": [0.28047794103622437], "accuracy": [0.8801067471504211], "val_loss": [0.16688956320285797], "val_accuracy": [0.9334837794303894]}, "date": "2025-05-05", "date_time": "01-13-09"}