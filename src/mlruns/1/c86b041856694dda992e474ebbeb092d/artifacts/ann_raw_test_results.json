{"data": {}, "embedding": {"vocabulary_size": 70, "embedding_dimension": 100}, "hiperparameter": {"model_summary": "Model: \"sequential\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n embedding (Embedding)       (None, 200, 100)          7100      \n                                                                 \n dense (Dense)               (None, 200, 128)          12928     \n                                                                 \n dense_1 (Dense)             (None, 200, 128)          16512     \n                                                                 \n dense_2 (Dense)             (None, 200, 128)          16512     \n                                                                 \n dense_3 (Dense)             (None, 200, 128)          16512     \n                                                                 \n dense_4 (Dense)             (None, 200, 128)          16512     \n                                                                 \n dense_5 (Dense)             (None, 200, 128)          16512     \n                                                                 \n dense_6 (Dense)             (None, 200, 128)          16512     \n                                                                 \n flatten (Flatten)           (None, 25600)             0         \n                                                                 \n dense_7 (Dense)             (None, 2)                 51202     \n                                                                 \n=================================================================\nTotal params: 170,302\nTrainable params: 170,302\nNon-trainable params: 0\n_________________________________________________________________\n", "epoch": 1, "train_batch_size": 64, "test_batch_size": 64, "sequence_length": 200}, "test_result": {"test_time": 20.300724983215332, "report": "              precision    recall  f1-score   support\n\n    phishing       0.88      0.88      0.88     28532\n  legitimate       0.85      0.85      0.85     22978\n\n    accuracy                           0.87     51510\n   macro avg       0.87      0.87      0.87     51510\nweighted avg       0.87      0.87      0.87     51510\n", "test_acc": 0.8673655390739441, "test_loss": 0.3113040328025818, "test_confusion_matrix": [[25067, 3465], [3367, 19611]]}, "epoch_history": {"loss": [0.33553335070610046], "accuracy": [0.852860689163208], "val_loss": [0.3059762120246887], "val_accuracy": [0.8679907321929932]}, "date": "2025-05-04", "date_time": "00-48-32"}