{"data": {}, "embedding": {"vocabulary_size": 70, "embedding_dimension": 100}, "hiperparameter": {"model_summary": "Model: \"sequential\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n embedding (Embedding)       (None, 200, 100)          7100      \n                                                                 \n dense (Dense)               (None, 200, 128)          12928     \n                                                                 \n dense_1 (Dense)             (None, 200, 128)          16512     \n                                                                 \n dense_2 (Dense)             (None, 200, 128)          16512     \n                                                                 \n dense_3 (Dense)             (None, 200, 128)          16512     \n                                                                 \n dense_4 (Dense)             (None, 200, 128)          16512     \n                                                                 \n dense_5 (Dense)             (None, 200, 128)          16512     \n                                                                 \n dense_6 (Dense)             (None, 200, 128)          16512     \n                                                                 \n flatten (Flatten)           (None, 25600)             0         \n                                                                 \n dense_7 (Dense)             (None, 2)                 51202     \n                                                                 \n=================================================================\nTotal params: 170,302\nTrainable params: 170,302\nNon-trainable params: 0\n_________________________________________________________________\n", "epoch": 5, "train_batch_size": 64, "test_batch_size": 64, "sequence_length": 200}, "test_result": {"test_time": 22.427088499069214, "report": "              precision    recall  f1-score   support\n\n    phishing       0.55      1.00      0.71     28532\n  legitimate       0.00      0.00      0.00     22978\n\n    accuracy                           0.55     51510\n   macro avg       0.28      0.50      0.36     51510\nweighted avg       0.31      0.55      0.39     51510\n", "test_acc": 0.8784701824188232, "test_loss": 0.28739669919013977, "test_confusion_matrix": [[28532, 0], [22978, 0]]}, "epoch_history": {"loss": [0.3107801377773285, 0.28132757544517517, 0.2761607766151428, 0.27198123931884766, 0.27018603682518005], "accuracy": [0.863580048084259, 0.8800545930862427, 0.8827152252197266, 0.8842198848724365, 0.8854280114173889], "val_loss": [0.2888617515563965, 0.2772614061832428, 0.27739670872688293, 0.2705400586128235, 0.282392293214798], "val_accuracy": [0.8751721382141113, 0.8822483420372009, 0.8830133080482483, 0.8863027691841125, 0.8790353536605835]}, "date": "2025-05-04", "date_time": "00-26-10"}