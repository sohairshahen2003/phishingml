{"data": {}, "embedding": {"vocabulary_size": 70, "embedding_dimension": 100}, "hiperparameter": {"model_summary": "Model: \"sequential\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n embedding (Embedding)       (None, 200, 100)          7100      \n                                                                 \n dense (Dense)               (None, 200, 128)          12928     \n                                                                 \n dense_1 (Dense)             (None, 200, 128)          16512     \n                                                                 \n dense_2 (Dense)             (None, 200, 128)          16512     \n                                                                 \n dense_3 (Dense)             (None, 200, 128)          16512     \n                                                                 \n dense_4 (Dense)             (None, 200, 128)          16512     \n                                                                 \n dense_5 (Dense)             (None, 200, 128)          16512     \n                                                                 \n dense_6 (Dense)             (None, 200, 128)          16512     \n                                                                 \n flatten (Flatten)           (None, 25600)             0         \n                                                                 \n dense_7 (Dense)             (None, 2)                 51202     \n                                                                 \n=================================================================\nTotal params: 170,302\nTrainable params: 170,302\nNon-trainable params: 0\n_________________________________________________________________\n", "epoch": 1, "train_batch_size": 32, "test_batch_size": 32, "sequence_length": 200}, "test_result": {"test_time": 25.284523248672485, "report": "              precision    recall  f1-score   support\n\n    phishing       0.55      1.00      0.71     28532\n  legitimate       0.00      0.00      0.00     22978\n\n    accuracy                           0.55     51510\n   macro avg       0.28      0.50      0.36     51510\nweighted avg       0.31      0.55      0.39     51510\n", "test_acc": 0.8633663654327393, "test_loss": 0.318680077791214, "test_confusion_matrix": [[28532, 0], [22978, 0]]}, "epoch_history": {"loss": [0.34260618686676025], "accuracy": [0.8491731286048889], "val_loss": [0.312937468290329], "val_accuracy": [0.8641944527626038]}, "date": "2025-05-03", "date_time": "20-44-18"}