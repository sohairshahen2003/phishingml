{"data": {}, "embedding": {"vocabulary_size": 70, "embedding_dimension": 100}, "hiperparameter": {"model_summary": "Model: \"sequential\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n embedding (Embedding)       (None, 200, 100)          7100      \n                                                                 \n conv1d (Conv1D)             (None, 198, 128)          38528     \n                                                                 \n max_pooling1d (MaxPooling1D  (None, 66, 128)          0         \n )                                                               \n                                                                 \n dropout (Dropout)           (None, 66, 128)           0         \n                                                                 \n conv1d_1 (Conv1D)           (None, 66, 128)           114816    \n                                                                 \n dropout_1 (Dropout)         (None, 66, 128)           0         \n                                                                 \n conv1d_2 (Conv1D)           (None, 66, 128)           82048     \n                                                                 \n dropout_2 (Dropout)         (None, 66, 128)           0         \n                                                                 \n conv1d_3 (Conv1D)           (None, 66, 128)           49280     \n                                                                 \n max_pooling1d_1 (MaxPooling  (None, 22, 128)          0         \n 1D)                                                             \n                                                                 \n dropout_3 (Dropout)         (None, 22, 128)           0         \n                                                                 \n conv1d_4 (Conv1D)           (None, 22, 128)           82048     \n                                                                 \n dropout_4 (Dropout)         (None, 22, 128)           0         \n                                                                 \n conv1d_5 (Conv1D)           (None, 22, 128)           49280     \n                                                                 \n max_pooling1d_2 (MaxPooling  (None, 7, 128)           0         \n 1D)                                                             \n                                                                 \n dropout_5 (Dropout)         (None, 7, 128)            0         \n                                                                 \n conv1d_6 (Conv1D)           (None, 7, 128)            49280     \n                                                                 \n max_pooling1d_3 (MaxPooling  (None, 2, 128)           0         \n 1D)                                                             \n                                                                 \n dropout_6 (Dropout)         (None, 2, 128)            0         \n                                                                 \n flatten (Flatten)           (None, 256)               0         \n                                                                 \n dense (Dense)               (None, 2)                 514       \n                                                                 \n=================================================================\nTotal params: 472,894\nTrainable params: 472,894\nNon-trainable params: 0\n_________________________________________________________________\n", "epoch": 8, "train_batch_size": 64, "test_batch_size": 64, "sequence_length": 200}, "test_result": {"test_time": 19.32854723930359, "report": "              precision    recall  f1-score   support\n\n    phishing       0.97      0.98      0.97     28532\n  legitimate       0.97      0.96      0.97     22978\n\n    accuracy                           0.97     51510\n   macro avg       0.97      0.97      0.97     51510\nweighted avg       0.97      0.97      0.97     51510\n", "test_acc": 0.9698893427848816, "test_loss": 0.07984834909439087, "test_confusion_matrix": [[27919, 613], [938, 22040]]}, "epoch_history": {"loss": [0.15873505175113678, 0.11321698129177094, 0.10242433100938797, 0.09759631752967834, 0.09300586581230164, 0.09094732999801636, 0.08890769630670547, 0.08908014744520187], "accuracy": [0.9353951811790466, 0.9551920890808105, 0.9594836831092834, 0.9613727927207947, 0.9636984467506409, 0.9645193815231323, 0.9650108814239502, 0.9652332663536072], "val_loss": [0.10853657871484756, 0.11624706536531448, 0.0889863520860672, 0.08494040369987488, 0.07776428759098053, 0.08044617623090744, 0.0800391435623169, 0.07943851500749588], "val_accuracy": [0.9563857913017273, 0.953096330165863, 0.9652501344680786, 0.9665697813034058, 0.9697253704071045, 0.9680615067481995, 0.9678893685340881, 0.9702225923538208]}, "date": "2025-05-04", "date_time": "17-53-31"}