{"data": {}, "embedding": {"vocabulary_size": 70, "embedding_dimension": 100}, "hiperparameter": {"model_summary": "Model: \"sequential\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n embedding (Embedding)       (None, 200, 100)          7100      \n                                                                 \n dense (Dense)               (None, 200, 128)          12928     \n                                                                 \n dense_1 (Dense)             (None, 200, 128)          16512     \n                                                                 \n dense_2 (Dense)             (None, 200, 128)          16512     \n                                                                 \n dense_3 (Dense)             (None, 200, 128)          16512     \n                                                                 \n dense_4 (Dense)             (None, 200, 128)          16512     \n                                                                 \n dense_5 (Dense)             (None, 200, 128)          16512     \n                                                                 \n dense_6 (Dense)             (None, 200, 128)          16512     \n                                                                 \n flatten (Flatten)           (None, 25600)             0         \n                                                                 \n dense_7 (Dense)             (None, 2)                 51202     \n                                                                 \n=================================================================\nTotal params: 170,302\nTrainable params: 170,302\nNon-trainable params: 0\n_________________________________________________________________\n", "epoch": 1, "train_batch_size": 64, "test_batch_size": 64, "sequence_length": 200}, "test_result": {"test_time": 21.116236925125122, "report": "              precision    recall  f1-score   support\n\n    phishing       0.89      0.86      0.88     28532\n  legitimate       0.83      0.87      0.85     22978\n\n    accuracy                           0.87     51510\n   macro avg       0.86      0.87      0.86     51510\nweighted avg       0.87      0.87      0.87     51510\n", "test_acc": 0.8655794858932495, "test_loss": 0.31479591131210327, "test_confusion_matrix": [[24546, 3986], [2938, 20040]]}, "epoch_history": {"loss": [0.33494389057159424], "accuracy": [0.8533411622047424], "val_loss": [0.31196945905685425], "val_accuracy": [0.8666137456893921]}, "date": "2025-05-04", "date_time": "02-29-47"}